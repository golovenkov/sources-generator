{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch-nlp char_language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import math \n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "eval_batch_size = 128\n",
    "sequence_length = 100\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# We will use torchnlp because it supports character-level encoding along with BPTT batch sampler\n",
    "from torchnlp.datasets import wikitext_2_dataset\n",
    "from torchnlp.text_encoders import CharacterEncoder\n",
    "from torchnlp.samplers import BPTTBatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sources_datasets(directory='./sources/'):\n",
    "    # Get list of files\n",
    "    sourcefiles = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    # shuffle\n",
    "    random.shuffle(sourcefiles)\n",
    "    train_dataset = []\n",
    "    for filename in sourcefiles:\n",
    "        with open(os.path.join(directory, filename), 'rt', encoding='utf-8', errors='ignore') as f:\n",
    "            train_dataset.extend(list(f.read()))\n",
    "    splt = int(len(train_dataset)*0.95)\n",
    "    return train_dataset[:splt], train_dataset[splt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = make_sources_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9047442, 476182)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CharacterEncoder(train_dataset + valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique tokens\n",
    "encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode dataset using character-level encoder\n",
    "train_data = encoder.encode(train_dataset)\n",
    "val_data = encoder.encode(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/', '*', ' ', 'V', 'e', 'r', 'i', 'f', 'y', ' ', 't', 'h', 'a', 't', ' ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  5,   6,   7,   8,   9,  10,  11,  12,  13,   7,  14,  15,\n",
       "         16,  14,   7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samplers\n",
    "train_source_sampler, val_source_sampler = tuple(\n",
    "    [BPTTBatchSampler(d, sequence_length, batch_size, True, 'source') for d in (train_dataset, valid_dataset)])\n",
    "\n",
    "train_target_sampler, val_target_sampler = tuple(\n",
    "    [BPTTBatchSampler(d, sequence_length, batch_size, True, 'target') for d in (train_dataset, valid_dataset)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, [slice(0, 100, None), slice(70683, 70783, None)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num of samples in a batch\n",
    "len(next(iter(train_source_sampler))), next(iter(train_source_sampler))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num of batches\n",
    "len(train_source_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  5,  36,  30,  ...,  28,  21,  29],\n",
      "        [  6,  53,  72,  ...,  28,   9,  29],\n",
      "        [  7,  28,  36,  ...,   5,  12,  58],\n",
      "        ...,\n",
      "        [  6,  50,  23,  ...,  37,  28,  19],\n",
      "        [  5,  53,  14,  ...,   7,  65,  19],\n",
      "        [ 28,   7,   9,  ...,   7,  11,   7]])\n",
      "tensor([[  6,  53,  72,  ...,  28,   9,  29],\n",
      "        [  7,  28,  36,  ...,   5,  12,  58],\n",
      "        [  8,  41,   7,  ...,   6,  11,  58],\n",
      "        ...,\n",
      "        [  5,  53,  14,  ...,   7,  65,  19],\n",
      "        [ 28,   7,   9,  ...,   7,  11,   7],\n",
      "        [ 28,  41,  21,  ...,   6,  22,  29]])\n"
     ]
    }
   ],
   "source": [
    "for source_sample, target_sample in zip(train_source_sampler, train_target_sampler):\n",
    "    print(torch.stack([train_data[i] for i in source_sample]).t_().contiguous()[:, :12])\n",
    "    print(torch.stack([train_data[i] for i in target_sample]).t_().contiguous()[:, :12])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/word_language_model/model.py\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
    "        else:\n",
    "            try:\n",
    "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
    "            except KeyError:\n",
    "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
    "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
    "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "\n",
    "        # Optionally tie weights as in:\n",
    "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
    "        # https://arxiv.org/abs/1608.05859\n",
    "        # and\n",
    "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
    "        # https://arxiv.org/abs/1611.01462\n",
    "        if tie_weights:\n",
    "            if nhid != ninp:\n",
    "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        emb = self.drop(self.encoder(x))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new(self.nlayers, bsz, self.nhid).zero_(),\n",
    "                    weight.new(self.nlayers, bsz, self.nhid).zero_())\n",
    "        else:\n",
    "            return weight.new(self.nlayers, bsz, self.nhid).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_source, source_sampler, target_sampler):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    ntokens = encoder.vocab_size\n",
    "    hidden = model.init_hidden(eval_batch_size)\n",
    "    for source_sample, target_sample in zip(source_sampler, target_sampler):\n",
    "        data = torch.stack([data_source[i] for i in source_sample]).t_().contiguous().to(device)                # source chars\n",
    "        targets = torch.stack([data_source[i] for i in target_sample]).t_().contiguous().view(-1).to(device)    # target chars\n",
    "        \n",
    "        output, hidden = model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        total_loss += criterion(output_flat, targets).item()\n",
    "    return total_loss / len(source_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_source, source_sampler, target_sampler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ntokens = encoder.vocab_size\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for batch, (source_sample, target_sample) in enumerate(zip(source_sampler, target_sampler)):        \n",
    "        data = torch.stack([data_source[i] for i in source_sample]).t_().contiguous().to(device)               # source chars\n",
    "        targets = torch.stack([data_source[i] for i in target_sample]).t_().contiguous().view(-1).to(device)   # target chars\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output, hidden = model(data)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(source_sampler), lr, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens:  111\n"
     ]
    }
   ],
   "source": [
    "ntokens = encoder.vocab_size; print(\"# tokens: \", ntokens)\n",
    "model = RNNModel('LSTM', ntokens, 1500, 1500, 2, 0.65, True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "grad_clip = 0.1\n",
    "lr = 20.\n",
    "best_val_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:\n",
      "  x << 0 || x < 2;\n",
      "}\n",
      "\n",
      "int test2(int y, int y, int z \n",
      "\n",
      "| epoch   1 |   100/  707 batches | lr 1.25 | loss  0.63 | ppl     1.87\n",
      "| epoch   1 |   200/  707 batches | lr 1.25 | loss  0.63 | ppl     1.88\n",
      "| epoch   1 |   300/  707 batches | lr 1.25 | loss  0.63 | ppl     1.87\n",
      "| epoch   1 |   400/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   1 |   500/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   1 |   600/  707 batches | lr 1.25 | loss  0.61 | ppl     1.84\n",
      "| epoch   1 |   700/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " index 300).\n",
      "   For hard-functions produce the line \n",
      "\n",
      "| epoch   2 |   100/  707 batches | lr 1.25 | loss  0.63 | ppl     1.87\n",
      "| epoch   2 |   200/  707 batches | lr 1.25 | loss  0.63 | ppl     1.88\n",
      "| epoch   2 |   300/  707 batches | lr 1.25 | loss  0.62 | ppl     1.87\n",
      "| epoch   2 |   400/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   2 |   500/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   2 |   600/  707 batches | lr 1.25 | loss  0.61 | ppl     1.84\n",
      "| epoch   2 |   700/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " \\]+\\[^\\n\\]*%ymm\\[0-9\\]\" } } */\n",
      "\n",
      "#include <immintri \n",
      "\n",
      "| epoch   3 |   100/  707 batches | lr 1.25 | loss  0.62 | ppl     1.87\n",
      "| epoch   3 |   200/  707 batches | lr 1.25 | loss  0.63 | ppl     1.87\n",
      "| epoch   3 |   300/  707 batches | lr 1.25 | loss  0.62 | ppl     1.87\n",
      "| epoch   3 |   400/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   3 |   500/  707 batches | lr 1.25 | loss  0.62 | ppl     1.85\n",
      "| epoch   3 |   600/  707 batches | lr 1.25 | loss  0.61 | ppl     1.84\n",
      "| epoch   3 |   700/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      "  TYPE in_a1, int *result)\n",
      "{\n",
      "  int *pf = (unsigned  \n",
      "\n",
      "| epoch   4 |   100/  707 batches | lr 1.25 | loss  0.62 | ppl     1.87\n",
      "| epoch   4 |   200/  707 batches | lr 1.25 | loss  0.63 | ppl     1.87\n",
      "| epoch   4 |   300/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   4 |   400/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   4 |   500/  707 batches | lr 1.25 | loss  0.62 | ppl     1.85\n",
      "| epoch   4 |   600/  707 batches | lr 1.25 | loss  0.61 | ppl     1.84\n",
      "| epoch   4 |   700/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " -O2 -fdump-tree-optimized\" } */\n",
      "\n",
      "#define N 16\n",
      "\n",
      "int \n",
      "\n",
      "| epoch   5 |   100/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   5 |   200/  707 batches | lr 1.25 | loss  0.63 | ppl     1.87\n",
      "| epoch   5 |   300/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   5 |   400/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   5 |   500/  707 batches | lr 1.25 | loss  0.62 | ppl     1.85\n",
      "| epoch   5 |   600/  707 batches | lr 1.25 | loss  0.61 | ppl     1.84\n",
      "| epoch   5 |   700/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      "  } */\n",
      "/* { dg-do link { target fpic } } */\n",
      "/* { dg \n",
      "\n",
      "| epoch   6 |   100/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   6 |   200/  707 batches | lr 1.25 | loss  0.62 | ppl     1.87\n",
      "| epoch   6 |   300/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   6 |   400/  707 batches | lr 1.25 | loss  0.62 | ppl     1.85\n",
      "| epoch   6 |   500/  707 batches | lr 1.25 | loss  0.62 | ppl     1.85\n",
      "| epoch   6 |   600/  707 batches | lr 1.25 | loss  0.61 | ppl     1.83\n",
      "| epoch   6 |   700/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " uire-effective-target powerpc_p9vector_ok } */\n",
      "/*  \n",
      "\n",
      "| epoch   7 |   100/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   7 |   200/  707 batches | lr 1.25 | loss  0.62 | ppl     1.87\n",
      "| epoch   7 |   300/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "| epoch   7 |   400/  707 batches | lr 1.25 | loss  0.62 | ppl     1.85\n",
      "| epoch   7 |   500/  707 batches | lr 1.25 | loss  0.61 | ppl     1.85\n",
      "| epoch   7 |   600/  707 batches | lr 1.25 | loss  0.60 | ppl     1.83\n",
      "| epoch   7 |   700/  707 batches | lr 1.25 | loss  0.62 | ppl     1.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " RIGNAL __inline\"\n",
      "/* { dg-do run } */\n",
      "\n",
      "extern void  \n",
      "\n",
      "| epoch   8 |   100/  707 batches | lr 0.31 | loss  0.62 | ppl     1.86\n",
      "| epoch   8 |   200/  707 batches | lr 0.31 | loss  0.62 | ppl     1.86\n",
      "| epoch   8 |   300/  707 batches | lr 0.31 | loss  0.62 | ppl     1.86\n",
      "| epoch   8 |   400/  707 batches | lr 0.31 | loss  0.61 | ppl     1.85\n",
      "| epoch   8 |   500/  707 batches | lr 0.31 | loss  0.61 | ppl     1.85\n",
      "| epoch   8 |   600/  707 batches | lr 0.31 | loss  0.60 | ppl     1.83\n",
      "| epoch   8 |   700/  707 batches | lr 0.31 | loss  0.61 | ppl     1.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      "  = x;\n",
      "  if (__builtin_isnensequar (x, y) != 3 || y \n",
      "\n",
      "| epoch   9 |   100/  707 batches | lr 0.08 | loss  0.62 | ppl     1.86\n",
      "| epoch   9 |   200/  707 batches | lr 0.08 | loss  0.62 | ppl     1.86\n",
      "| epoch   9 |   300/  707 batches | lr 0.08 | loss  0.62 | ppl     1.86\n",
      "| epoch   9 |   400/  707 batches | lr 0.08 | loss  0.61 | ppl     1.85\n",
      "| epoch   9 |   500/  707 batches | lr 0.08 | loss  0.61 | ppl     1.84\n",
      "| epoch   9 |   600/  707 batches | lr 0.08 | loss  0.60 | ppl     1.83\n",
      "| epoch   9 |   700/  707 batches | lr 0.08 | loss  0.61 | ppl     1.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | valid loss  0.64 | valid ppl     1.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " RP test integer types.  Make sure we can output ha \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('sample:\\n', generate(50), '\\n')\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    train(train_data, train_source_sampler, train_target_sampler)          # train\n",
    "    val_loss = evaluate(val_data, val_source_sampler, val_target_sampler)  # validate\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n",
    "        epoch, val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "    else:\n",
    "        # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "        lr /= 4.0\n",
    "    with torch.no_grad():\n",
    "        print('sample:\\n', generate(50), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n=50, temp=1.):\n",
    "    model.eval()\n",
    "    x = torch.rand(1, 1).mul(ntokens).long().to(device) # init hidden state and cell state with zeros for batch_size = 1\n",
    "    hidden = model.init_hidden(1)   # pass random token\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        output, hidden = model(x, hidden)\n",
    "        # output is a Tensor of shape [seq_len, batch_size, vocab_len] of tokens' probabilities\n",
    "        s_weights = output.squeeze().data.div(temp).exp()\n",
    "        # sample from multinomial distribution, then take the first element of the array\n",
    "        s_idx = torch.multinomial(s_weights, 1)[0]\n",
    "        x.data.fill_(s_idx)\n",
    "        s = encoder.itos[s_idx]\n",
    "        out.append(s)\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = generate(10000, 1.)\n",
    "t15 = generate(10000, 1.5)\n",
    "t075 = generate(10000, 0.75)\n",
    "with open('./generated075-char.txt', 'w') as outf:\n",
    "    outf.write(t075)\n",
    "with open('./generated1-char.txt', 'w') as outf:\n",
    "    outf.write(t1)\n",
    "with open('./generated15-char.txt', 'w') as outf:\n",
    "    outf.write(t15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return prc3205;\r\n",
      "  return 1029;\r\n",
      "}\r\n",
      "\r\n",
      "int main(void)\r\n",
      "{\r\n",
      "  bugger(1);\r\n",
      "}\r\n",
      "/* { dg-do run { target { powerpc64le-*-* && powerpc_epthr } } } */\r\n",
      "/* { dg-do compile } */\r\n"
     ]
    }
   ],
   "source": [
    "!head generated1-char.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hound int ,(unsigned phaif2)en200040UL_) && (count == 477)\r\n",
      "    *((MINVALorO(1) + 1 + 19 & file (!x->ump)))\r\n",
      "    ) !> )\r\n",
      "\tunmined_TYPE__ ilemin[f->i * 8]. 0 = jXlLsuct>tilfbarv4;\r\n",
      "\r\n",
      "\tGMjT_hw (t*, sqdo);\r\n",
      "\r\n",
      " ic > widChCountKreaDROpIrsin1;\r\n",
      "  where A_tlr_tag (5mofme);\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head generated15-char.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORKAROUND_SPECULATIVE_SYNCS is defined\"\r\n",
      "#endif\r\n",
      "\r\n",
      "#if __SILICON_REVISION__ != 0x0001\r\n",
      "#error \"__SILICON_REVISION__ is not 0x0004\"\r\n",
      "#endif\r\n",
      "\r\n",
      "#ifndef __WORKAROUNDS_ENABLED\r\n",
      "#error \"__WORKAROUNDS_ENABLED is not defined\"\r\n",
      "#endif\r\n"
     ]
    }
   ],
   "source": [
    "!head generated075-char.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
