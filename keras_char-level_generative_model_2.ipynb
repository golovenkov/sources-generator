{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras char-level generative model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import math \n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "eval_batch_size = 128\n",
    "sequence_length = 100\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use torchnlp because it supports character-level encoding along with BPTT batch sampler\n",
    "from torchnlp.text_encoders import CharacterEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Larger LSTM network and generate text\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sources_datasets(directory='./sources/', split_ratio=0.95):\n",
    "    # Get list of files\n",
    "    sourcefiles = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    # shuffle\n",
    "    random.shuffle(sourcefiles)\n",
    "    train_dataset = []\n",
    "    for filename in sourcefiles:\n",
    "        with open(os.path.join(directory, filename), 'rt', encoding='utf-8', errors='ignore') as f:\n",
    "            train_dataset.extend(list(f.read()))\n",
    "    splt = int(len(train_dataset) * split_ratio)\n",
    "    return train_dataset[:splt], train_dataset[splt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9047442, 476182)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, valid_dataset = make_sources_datasets()\n",
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CharacterEncoder(train_dataset + valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique tokens\n",
    "encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode dataset using character-level encoder\n",
    "train_data = encoder.encode(train_dataset)\n",
    "val_data = encoder.encode(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "def prepare_inputs(data, seq_length = 100):\n",
    "    n_chars = len(data)\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    n_chars = len(data)\n",
    "    for i in range(0, n_chars - seq_length, 1):\n",
    "        seq_in = data[i:i + seq_length]\n",
    "        seq_out = data[i + seq_length]\n",
    "        dataX.append(seq_in)\n",
    "        dataY.append(seq_out)\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataX, train_dataY = prepare_inputs(train_data)\n",
    "valid_dataX, valid_dataY = prepare_inputs(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13,  8, 14, 15,  5,  6,  7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ouble fabs(double);\\n\\nvoid test_coms(void);\\n\\nextern void abort(void);\\n\\nstruct {double r, s; } com;    '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(train_dataset[1:102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ouble fabs(double);\\n\\nvoid test_coms(void);\\n\\nextern void abort(void);\\n\\nstruct {double r, s; } com;   ',\n",
       " ' ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([encoder.itos[x] for x in train_dataX[1]]), encoder.itos[train_dataY[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data, val_data, train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples:  9047342\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(train_dataX)\n",
    "print(\"Total train samples: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X_train = np.reshape(np.asarray([np.asarray(sample) for sample in train_dataX]), (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouble fabs(double);\n",
      "\n",
      "void test_coms(void);\n",
      "\n",
      "extern void abort(void);\n",
      "\n",
      "struct {double r, s; } com;   \n"
     ]
    }
   ],
   "source": [
    "print(\"\".join([encoder.itos[x] for x in X_train[1].squeeze()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "X_train = X_train / float(encoder.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid samples:  476082\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(valid_dataX)\n",
    "print(\"Total valid samples: \", n_patterns)\n",
    "X_valid = np.reshape(np.asarray([np.asarray(sample) for sample in valid_dataX]), (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "X_valid = X_valid / float(encoder.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(train_dataY + valid_dataY)\n",
    "y_train, y_valid = y[:len(train_dataY)], y[len(train_dataY):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9047342, 111), (476082, 111))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1], X_train.shape[2], ), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min', baseline=None)\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9047342 samples, validate on 476082 samples\n",
      "Epoch 1/20\n",
      "9047342/9047342 [==============================] - 5461s 604us/step - loss: 1.8103 - val_loss: 1.2101\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.21008, saving model to weights-improvement-01-1.2101-bigger.hdf5\n",
      "Epoch 2/20\n",
      "9047342/9047342 [==============================] - 5116s 565us/step - loss: 1.2258 - val_loss: 1.0553\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.21008 to 1.05529, saving model to weights-improvement-02-1.0553-bigger.hdf5\n",
      "Epoch 3/20\n",
      "9047342/9047342 [==============================] - 5118s 566us/step - loss: 1.1216 - val_loss: 1.0006\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.05529 to 1.00055, saving model to weights-improvement-03-1.0006-bigger.hdf5\n",
      "Epoch 4/20\n",
      "9047342/9047342 [==============================] - 5128s 567us/step - loss: 2.8521 - val_loss: 2.7299\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00055\n",
      "Epoch 5/20\n",
      "  46080/9047342 [..............................] - ETA: 1:24:23 - loss: 2.9126"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9f5cb51ea734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m          )\n",
      "\u001b[0;32m/home/evgeny/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/evgeny/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evgeny/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evgeny/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evgeny/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=20, \n",
    "          batch_size=1024, \n",
    "          callbacks=callbacks_list,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_valid, y_valid)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-03-1.0006-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 51 21 13 26 36 10 21 11  9 54 65 77 11 30 11 32 31 18 31]\n",
      "/\n",
      "/* { dg-options \"-O3 -mpower8-vector -Wno-psabi\" } */\n",
      "/* { dg-require-effective-target lp64 } */\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "# start = numpy.random.randint(0, len(dataX)-1)\n",
    "# pattern = dataX[start]\n",
    "# pattern = \"int main(void)\\n{\"\n",
    "# if len(pattern) < 100:\n",
    "#     pattern = \" \"*(100 - len(pattern)) + pattern\n",
    "# pattern = [encoder.stoi[s] for s in pattern]\n",
    "pattern = np.asarray(train_dataX[1555])\n",
    "print(pattern[-20:])\n",
    "print(\"\".join([encoder.itos[i] for i in pattern]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ile } */\n",
      "/* { dg-options \"-O2 -mavx512vl\" } */\n",
      "/* { dg-final { scan-assembler-times \"vpmovsqd\\[ \\\\t\\]+\\[^\\{\\n\\]*%zmm\\[0-9\\]+\\{%k\\[1-7\\]\\}(?:\\n|\\[ \\\\t\\]+#)\" 1 } } */\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "volatile __m256i x256;\n",
      "volatile __mmask8 m;\n",
      "\n",
      "void extern\n",
      "avx512vl_test (void)\n",
      "{\n",
      "  x = _mm512_mask_ara_attepi32 (x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, m, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "}\n",
      "/* { dg-do compile } */\n",
      "/* { dg-options \"-O2 -mavx512vl\" } */\n",
      "/* { dg-final { scan-assembler-times \"vpmovsqd\\[ \\\\t\\]+\\[^\\{\\n\\]*%zmm\\[0-9\\]+\\{%k\\[1-7\\]\\}(?:\\n|\\[ \\\\t\\]+#)\" 1 } } */\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "volatile __m256i x256;\n",
      "volatile __mmask8 m;\n",
      "\n",
      "void extern\n",
      "avx512vl_test (void)\n",
      "{\n",
      "  x = _mm512_mask_ara_attepi32 (x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, m, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "}\n",
      "/* { dg-do compile } */\n",
      "/* { dg-options \"-O2 -mavx512vl\" } */\n",
      "/* { dg-final { scan-assembler-times \"vpmovsqd\\[ \\\\t\\]+\\[^\\{\\n\\]*%zmm\\[0-9\\]+\\{%k\\[1-7\\]\\}(?:\\n|\\[ \\\\t\\]+#)\" 1 } } */\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "volatile __m256i x256;\n",
      "volatile __mmask8 m;\n",
      "\n",
      "void extern\n",
      "avx512vl_test (void)\n",
      "{\n",
      "  x = _mm512_mask_ara_attepi32 (x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, m, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "}\n",
      "/* { dg-do compile } */\n",
      "/* { dg-options \"-O2 -mavx512vl\" } */\n",
      "/* { dg-final { scan-assembler-times \"vpmovsqd\\[ \\\\t\\]+\\[^\\{\\n\\]*%zmm\\[0-9\\]+\\{%k\\[1-7\\]\\}(?:\\n|\\[ \\\\t\\]+#)\" 1 } } */\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "volatile __m256i x256;\n",
      "volatile __mmask8 m;\n",
      "\n",
      "void extern\n",
      "avx512vl_test (void)\n",
      "{\n",
      "  x = _mm512_mask_ara_attepi32 (x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, m, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "}\n",
      "/* { dg-do compile } */\n",
      "/* { dg-options \"-O2 -mavx512vl\" } */\n",
      "/* { dg-final { scan-assembler-times \"vpmovsqd\\[ \\\\t\\]+\\[^\\{\\n\\]*%zmm\\[0-9\\]+\\{%k\\[1-7\\]\\}(?:\\n|\\[ \\\\t\\]+#)\" 1 } } */\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "volatile __m256i x256;\n",
      "volatile __mmask8 m;\n",
      "\n",
      "void extern\n",
      "avx512vl_test (void)\n",
      "{\n",
      "  x = _mm512_mask_ara_attepi32 (x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, m, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "}\n",
      "/* { dg-do compile } */\n",
      "/* { dg-options \"-O2 -mavx512vl\" } */\n",
      "/* { dg-final { scan-assembler-times \"vpmovsqd\\[ \\\\t\\]+\\[^\\{\\n\\]*%zmm\\[0-9\\]+\\{%k\\[1-7\\]\\}(?:\\n|\\[ \\\\t\\]+#)\" 1 } } */\n",
      "\n",
      "#include <immintrin.h>\n",
      "\n",
      "volatile __m256i x256;\n",
      "volatile __mmask8 m;\n",
      "\n",
      "void extern\n",
      "avx512vl_test (void)\n",
      "{\n",
      "  x = _mm512_mask_ara_attepi32 (x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, m, x, x);\n",
      "  x = _mm512_maskz_mal__epi32 (x, x, x, x, x);\n",
      "  x = _mm512_maskz_mor_epi32 (x, x, x);\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "text = \"\"\n",
    "for i in range(3000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(encoder.vocab_size)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)   # here we do not use temperature\n",
    "    result = encoder.itos[index]\n",
    "    text += result\n",
    "    pattern = np.append(pattern, index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drawbacks: \n",
    "* to generate 3000 chars we should run the model (3000-100)=2900 times;\n",
    "* the model repeats learned patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
